{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subclassing Models in Deep Learning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Subclassing is an advanced and flexible approach to building neural networks. Unlike sequential models which are limited to linear layer stacking, subclassing allows for creating custom model architectures with complex topologies, branching paths, and sophisticated control flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Foundation\n",
    "\n",
    "Unlike sequential models where data flows linearly, subclassed models can implement arbitrary functions $f_\\theta: X \\rightarrow Y$ mapping inputs to outputs.\n",
    "\n",
    "For a model with multiple branches and paths, we can represent the computation as a directed graph where each node is a layer or operation:\n",
    "\n",
    "- For a model with branching paths, the output at a given node can be expressed as:\n",
    "$$h_i = f_i\\left(\\{h_j : j \\in \\text{parents}(i)\\}\\right)$$\n",
    "\n",
    "- For layers with multiple inputs (e.g., concatenation or addition), we might have:\n",
    "$$h_i = g_i\\left(h_{j_1}, h_{j_2}, \\ldots, h_{j_k}\\right)$$\n",
    "\n",
    "- For skip connections (as in ResNets), we could have:\n",
    "$$h_i = \\sigma(W_i h_{i-1} + h_{i-2} + b_i)$$\n",
    "\n",
    "This flexibility allows for implementing complex architectures like ResNets, Inception models, or custom research architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Representation\n",
    "\n",
    "Subclassing allows for complex model architectures with branching paths and skip connections:\n",
    "\n",
    "```mermaid\n",
    "flowchart TB\n",
    "    Input((\"Input\")) --> Conv1[\"Conv1\"]\n",
    "    Conv1 --> Conv2A[\"Conv2A\"]\n",
    "    Conv1 --> Conv2B[\"Conv2B\"]\n",
    "    Conv2A --> Conv3A[\"Conv3A\"]\n",
    "    Conv2B --> Conv3B[\"Conv3B\"]\n",
    "    Conv1 --> |\"Skip Connection\"| Add\n",
    "    Conv3A --> Add{{\"+\"}}\n",
    "    Conv3B --> Add\n",
    "    Add --> Output((\"Output\"))\n",
    "    style Input fill:#f5f5f5,stroke:#333,stroke-width:1px,color:black\n",
    "    style Output fill:#f5f5f5,stroke:#333,stroke-width:1px,color:black\n",
    "    style Add fill:#ffcc99,stroke:#333,stroke-width:1px,color:black\n",
    "    style Conv1 fill:#bbdefb,stroke:#333,stroke-width:1px,color:black\n",
    "    style Conv2A fill:#bbdefb,stroke:#333,stroke-width:1px,color:black\n",
    "    style Conv2B fill:#bbdefb,stroke:#333,stroke-width:1px,color:black\n",
    "    style Conv3A fill:#bbdefb,stroke:#333,stroke-width:1px,color:black\n",
    "    style Conv3B fill:#bbdefb,stroke:#333,stroke-width:1px,color:black\n",
    "```\n",
    "\n",
    "A more detailed diagram showing a residual block in a subclassed model:\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    Input((\"x\")) --> Conv1[\"Conv2D\"] --> BN1[\"BatchNorm\"] --> ReLU1[\"ReLU\"]\n",
    "    ReLU1 --> Conv2[\"Conv2D\"] --> BN2[\"BatchNorm\"]\n",
    "    Input --> |\"Identity\"| Add{{\"+\"}}\n",
    "    BN2 --> Add --> ReLU2[\"ReLU\"] --> Output((\"output\"))\n",
    "    style Input fill:#f5f5f5,stroke:#333,stroke-width:1px,color:black\n",
    "    style Output fill:#f5f5f5,stroke:#333,stroke-width:1px,color:black\n",
    "    style Conv1 fill:#bbdefb,stroke:#333,stroke-width:1px,color:black\n",
    "    style Conv2 fill:#bbdefb,stroke:#333,stroke-width:1px,color:black\n",
    "    style BN1 fill:#dcedc8,stroke:#333,stroke-width:1px,color:black\n",
    "    style BN2 fill:#dcedc8,stroke:#333,stroke-width:1px,color:black\n",
    "    style ReLU1 fill:#ffe0b2,stroke:#333,stroke-width:1px,color:black\n",
    "    style ReLU2 fill:#ffe0b2,stroke:#333,stroke-width:1px,color:black\n",
    "    style Add fill:#ffcc99,stroke:#333,stroke-width:1px,color:black\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation with PyTorch\n",
    "\n",
    "PyTorch's object-oriented design makes subclassing natural through the extension of the `nn.Module` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicNet(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class BasicNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate=0.2):\n",
    "        super(BasicNet, self).__init__()\n",
    "        \n",
    "        # Define layers as class attributes\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Keep configuration for later reference\n",
    "        self.config = {\n",
    "            \"input_size\": input_size,\n",
    "            \"hidden_size\": hidden_size,\n",
    "            \"output_size\": output_size,\n",
    "            \"dropout_rate\": dropout_rate\n",
    "        }\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Define the forward pass with custom logic\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    # Custom methods can be added\n",
    "    def get_config(self):\n",
    "        return self.config\n",
    "\n",
    "# Create the model\n",
    "model = BasicNet(input_size=784, hidden_size=128, output_size=10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Subclassing Patterns\n",
    "\n",
    "### Multi-Input and Multi-Output Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIMONet(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (image_fc): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  (meta_fc1): Linear(in_features=10, out_features=64, bias=True)\n",
      "  (meta_fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (combined_fc): Linear(in_features=160, out_features=128, bias=True)\n",
      "  (class_output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (reg_output): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MIMONet(nn.Module):\n",
    "    \"\"\"Multi-Input Multi-Output Network\"\"\"\n",
    "    def __init__(self):\n",
    "        super(MIMONet, self).__init__()\n",
    "        \n",
    "        # Image processing branch\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.image_fc = nn.Linear(64 * 7 * 7, 128)\n",
    "        \n",
    "        # Metadata processing branch\n",
    "        self.meta_fc1 = nn.Linear(10, 64)\n",
    "        self.meta_fc2 = nn.Linear(64, 32)\n",
    "        \n",
    "        # Combined processing\n",
    "        self.combined_fc = nn.Linear(128 + 32, 128)\n",
    "        \n",
    "        # Multiple output heads\n",
    "        self.class_output = nn.Linear(128, 10)  # Classification head\n",
    "        self.reg_output = nn.Linear(128, 1)     # Regression head\n",
    "    \n",
    "    def forward(self, image, metadata):\n",
    "        # Process image\n",
    "        img = F.relu(self.conv1(image))\n",
    "        img = self.pool(img)\n",
    "        img = F.relu(self.conv2(img))\n",
    "        img = self.pool(img)\n",
    "        img = img.view(img.size(0), -1)  # Flatten\n",
    "        img = F.relu(self.image_fc(img))\n",
    "        \n",
    "        # Process metadata\n",
    "        meta = F.relu(self.meta_fc1(metadata))\n",
    "        meta = F.relu(self.meta_fc2(meta))\n",
    "        \n",
    "        # Combine features\n",
    "        combined = torch.cat([img, meta], dim=1)\n",
    "        combined = F.relu(self.combined_fc(combined))\n",
    "        \n",
    "        # Generate outputs\n",
    "        class_output = self.class_output(combined)\n",
    "        reg_output = self.reg_output(combined)\n",
    "        \n",
    "        return class_output, reg_output\n",
    "\n",
    "# To demonstrate the model shape:\n",
    "mimo_model = MIMONet()\n",
    "print(mimo_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a ResNet Block\n",
    "\n",
    "ResNets use skip connections that are easily implemented with subclassing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet architecture:\n",
      "SimpleResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=6272, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        # Main path\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                              stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                              stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Shortcut connection (skip connection)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        # If dimensions change, we need to adjust the shortcut path\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                         stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Store input for skip connection\n",
    "        shortcut = x\n",
    "        \n",
    "        # Main path\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        \n",
    "        # Add skip connection\n",
    "        out += self.shortcut(shortcut)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Build a simple ResNet\n",
    "class SimpleResNet(nn.Module):\n",
    "    def __init__(self, num_blocks=2, num_classes=10):\n",
    "        super(SimpleResNet, self).__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Stacking residual blocks\n",
    "        self.layer1 = self._make_layer(64, num_blocks, stride=1)\n",
    "        self.layer2 = self._make_layer(128, num_blocks, stride=2)\n",
    "        \n",
    "        self.fc = nn.Linear(128 * 7 * 7, num_classes)\n",
    "    \n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        # Create a layer with multiple residual blocks\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(ResidualBlock(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)  # Flatten\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "resnet = SimpleResNet()\n",
    "print(\"ResNet architecture:\")\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Subclassed Model\n",
    "\n",
    "Below is an example of training a subclassed model on the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready for training with MNIST dataset.\n"
     ]
    }
   ],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "        # Add metrics tracking\n",
    "        self.train_accuracy = []\n",
    "        self.val_accuracy = []\n",
    "        self.losses = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten the features\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    # Custom method for feature extraction\n",
    "    def extract_features(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = self.features(x)\n",
    "            return x.view(x.size(0), -1)  # Return flattened features\n",
    "\n",
    "# Create the model and define training components\n",
    "model = MNISTClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function with progress tracking\n",
    "def train_model(model, train_loader, val_loader=None, epochs=3):\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            if i % 100 == 99:  # Print every 100 mini-batches\n",
    "                print(f'Epoch {epoch+1}, Batch {i+1}: Loss = {running_loss/100:.4f}, '\n",
    "                      f'Accuracy = {100*correct/total:.2f}%')\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        # Save epoch statistics\n",
    "        train_acc = 100 * correct / total\n",
    "        train_accs.append(train_acc)\n",
    "        \n",
    "        # Validation\n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    outputs = model(inputs)\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            val_acc = 100 * correct / total\n",
    "            val_accs.append(val_acc)\n",
    "            print(f'Epoch {epoch+1}: Validation Accuracy = {val_acc:.2f}%')\n",
    "    \n",
    "    # Store metrics in the model for later use\n",
    "    model.train_accuracy = train_accs\n",
    "    if val_loader:\n",
    "        model.val_accuracy = val_accs\n",
    "    \n",
    "    return train_accs, val_accs\n",
    "\n",
    "# Setup data loaders (commented out as it requires the MNIST dataset)\n",
    "\"\"\"\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000)\n",
    "\n",
    "# Train the model\n",
    "train_accs, val_accs = train_model(model, train_loader, test_loader, epochs=3)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Model ready for training with MNIST dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and Evaluation\n",
    "\n",
    "Subclassed models can implement custom inference methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference model ready for evaluation.\n",
      "\n",
      "Predictions: tensor([3, 3, 3, 3, 3])\n",
      "Confidence scores: tensor([0.1214, 0.1248, 0.1190, 0.1214, 0.1272])\n"
     ]
    }
   ],
   "source": [
    "class InferenceModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super(InferenceModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        # Turn off gradient tracking for inference\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "    \n",
    "    def predict(self, x, return_confidence=False):\n",
    "        \"\"\"Custom prediction method with confidence scores\"\"\"\n",
    "        self.eval()  # Set to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            logits = self(x)\n",
    "            probabilities = F.softmax(logits, dim=1)\n",
    "            confidences, predictions = torch.max(probabilities, dim=1)\n",
    "            \n",
    "            if return_confidence:\n",
    "                return predictions, confidences\n",
    "            return predictions\n",
    "    \n",
    "    def predict_batch(self, dataloader):\n",
    "        \"\"\"Predict on a full batch of data\"\"\"\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        \n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader:\n",
    "                predictions = self.predict(inputs)\n",
    "                all_predictions.append(predictions)\n",
    "                all_labels.append(labels)\n",
    "                \n",
    "        return torch.cat(all_predictions), torch.cat(all_labels)\n",
    "    \n",
    "    def evaluate(self, dataloader):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        predictions, labels = self.predict_batch(dataloader)\n",
    "        correct = (predictions == labels).sum().item()\n",
    "        total = labels.size(0)\n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'correct': correct,\n",
    "            'total': total\n",
    "        }\n",
    "\n",
    "# Create an inference model wrapper around our classifier\n",
    "inference_model = InferenceModel(model)\n",
    "print(\"Inference model ready for evaluation.\")\n",
    "\n",
    "# Example of synthetic data for demonstration\n",
    "dummy_input = torch.randn(5, 1, 28, 28)  # 5 MNIST-like images\n",
    "predictions, confidences = inference_model.predict(dummy_input, return_confidence=True)\n",
    "print(f\"\\nPredictions: {predictions}\")\n",
    "print(f\"Confidence scores: {confidences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages and Limitations of Subclassing\n",
    "\n",
    "### Advantages\n",
    "- **Maximum Flexibility**: Can implement any architecture or computational graph\n",
    "- **Code Reusability**: Can create class hierarchies and reuse components\n",
    "- **Dynamic Behavior**: Can implement conditional computation paths\n",
    "- **Complex Topologies**: Supports skip connections, branches, and custom operations\n",
    "- **Custom Methods**: Can add domain-specific utility functions to models\n",
    "\n",
    "### Limitations\n",
    "- **Complexity**: More complex implementation than sequential models\n",
    "- **Debugging Challenges**: Harder to trace through custom forward logic\n",
    "- **Serialization Issues**: Custom methods may require special handling during saving/loading\n",
    "- **Potentially Slower**: May not benefit from certain optimizations available to static graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Subclassing provides the ultimate flexibility in designing neural network architectures. It allows for:\n",
    "\n",
    "1. Implementation of custom architectures with complex topologies\n",
    "2. Addition of domain-specific methods and behaviors to models\n",
    "3. Creation of models with multiple inputs and outputs\n",
    "4. Development of sophisticated architectures like ResNets, Inception models, or custom research designs\n",
    "\n",
    "While it requires more code and understanding compared to sequential models, the flexibility and power it offers make it the preferred approach for advanced deep learning architectures and research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Basic**: Implement a simple feed-forward neural network using subclassing and compare it to an equivalent sequential model.\n",
    "\n",
    "2. **Intermediate**: Modify the ResidualBlock to create a \"DenseBlock\" that concatenates the input with the output instead of adding them.\n",
    "\n",
    "3. **Advanced**: Implement a U-Net architecture for image segmentation using subclassing, with encoder and decoder paths and skip connections.\n",
    "\n",
    "4. **Research**: Design and implement a custom attention mechanism within a subclassed model for sequence-to-sequence tasks."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
