{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnoejh/AI/blob/main/Book/1.introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# 1. Introduction to Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## 1.1 What is Deep Learning?\n",
        "\n",
        "Deep learning is a subset of machine learning that uses artificial neural networks to learn hierarchical representations of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "### Deep Learning Pipeline\n",
        "\n",
        "<div class=\"zoomable-mermaid\">\n",
        "\n",
        "```mermaid\n",
        "graph LR\n",
        "    subgraph Input\n",
        "        A[Raw Data]\n",
        "    end\n",
        "    subgraph Hidden Layers\n",
        "        B[Simple Features]\n",
        "        C[Complex Features]\n",
        "        D[Abstract Concepts]\n",
        "    end\n",
        "    subgraph Output\n",
        "        E[Predictions]\n",
        "    end\n",
        "    A --> B --> C --> D --> E\n",
        "```\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "### Neural Networks Architecture\n",
        "\n",
        "A neural network consists of:\n",
        "1. Input Layer: Receives raw data\n",
        "2. Hidden Layers: Processes and transforms data\n",
        "3. Output Layer: Produces final predictions\n",
        "4. Weights & Biases: Learnable parameters\n",
        "5. Activation Functions: Non-linear transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModernNN(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.3, inplace=False)\n",
            "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
            "    (5): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ModernNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(ModernNN, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(hidden_size),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_size, num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Example usage\n",
        "model = ModernNN(784, 256, 10)  # MNIST-like architecture\n",
        "print(model)  # Print the model architecture\n",
        "x = torch.randn(64, 784)  # 64 samples with 784 features each\n",
        "y = model(x)  # Forward pass\n",
        "print(y.shape)  # torch.Size([64, 10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "### Types of Deep Learning\n",
        "\n",
        "| Type | Description | Common Applications | Key Architectures |\n",
        "|------|-------------|---------------------|-------------------|\n",
        "| Supervised | Learning from labeled data | Classification, Regression | CNN, RNN |\n",
        "| Unsupervised | Finding patterns in unlabeled data | Clustering, Dimensionality Reduction | Autoencoder, GAN |\n",
        "| Self-Supervised | Learning from data's inherent structure | Pre-training, Representation Learning | BERT, SimCLR |\n",
        "| Reinforcement | Learning through environment interaction | Game AI, Robotics | DQN, PPO |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "### Evolution of Modern AI (2012-Present)\n",
        "\n",
        "<div class=\"zoomable-mermaid\">\n",
        "\n",
        "```mermaid\n",
        "timeline\n",
        "    title Major Deep Learning & AI Breakthroughs\n",
        "    2012 : AlexNet\n",
        "         : Deep Learning Revolution Begins\n",
        "    2014 : GANs Introduced\n",
        "         : Deep Learning for Image Generation\n",
        "    2017 : Transformer Architecture\n",
        "         : Attention Is All You Need\n",
        "    2018 : BERT\n",
        "         : Transfer Learning in NLP\n",
        "    2019 : GPT-2\n",
        "         : Large Language Models Emerge\n",
        "    2020 : GPT-3 & DDPM\n",
        "         : Few-shot Learning & Novel Diffusion Models\n",
        "    2021 : DALL-E\n",
        "         : Text-to-Image Generation\n",
        "    2022 : ChatGPT & Stable Diffusion\n",
        "         : AI Goes Mainstream\n",
        "    2023 : GPT-4 & Gemini\n",
        "         : Multimodal AI Systems\n",
        "    2024 : Sora & Claude 3\n",
        "         : Text-to-Video & Advanced Reasoning\n",
        "```\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "#### Key Modern AI Paradigms\n",
        "\n",
        "| Year | Technology | Impact | Key Innovation |\n",
        "|------|------------|---------|----------------|\n",
        "| 2017-2019 | Transformers & BERT | NLP Revolution | Attention Mechanism |\n",
        "| 2020-2022 | Large Language Models | General AI Assistants | Scale & Transfer Learning |\n",
        "| 2022-2023 | Diffusion Models | Creative AI | Controlled Generation |\n",
        "| 2023-2024 | Multimodal AI | Cross-domain Understanding | Multi-task Learning |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "#### Modern AI Capabilities\n",
        "\n",
        "<div class=\"zoomable-mermaid\">\n",
        "\n",
        "```mermaid\n",
        "mindmap\n",
        "  root((Modern AI))\n",
        "    Language\n",
        "      Chat & Dialogue\n",
        "      Code Generation\n",
        "      Translation\n",
        "    Vision\n",
        "      Image Generation\n",
        "      Video Synthesis\n",
        "      3D Modeling\n",
        "    Audio\n",
        "      Speech Recognition\n",
        "      Music Generation\n",
        "      Voice Synthesis\n",
        "    Multimodal\n",
        "      Text-to-Image\n",
        "      Text-to-Video\n",
        "      Cross-modal Understanding\n",
        "```\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "#### Emerging Trends\n",
        "- Agent-based AI: Autonomous systems that can plan and execute complex tasks\n",
        "- Multimodal Learning: Integration of different types of data and modalities\n",
        "## 1.2 Deep Learning vs Traditional Machine Learning\n",
        "\n",
        "### Key Differences:\n",
        "\n",
        "```mermaid\n",
        "graph TB\n",
        "    subgraph Traditional ML\n",
        "        A1[Feature Extraction] --> B1[Feature Engineering]\n",
        "        B1 --> C1[Model Training]\n",
        "    end\n",
        "    subgraph Deep Learning\n",
        "        A2[Raw Data] --> B2[Automatic Feature Learning]\n",
        "        B2 --> C2[End-to-End Training]\n",
        "    end\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "| Aspect | Traditional ML | Deep Learning |\n",
        "|--------|----------------|---------------|\n",
        "| Feature Engineering | Manual | Automatic |\n",
        "| Data Requirements | Small to Medium | Large |\n",
        "| Interpretability | Higher | Lower |\n",
        "| Training Time | Faster | Slower |\n",
        "| Hardware Requirements | CPU sufficient | GPU/TPU preferred |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## 1.3 Modern Applications\n",
        "\n",
        "### Computer Vision\n",
        "- Object Detection\n",
        "- Image Segmentation\n",
        "- Face Recognition\n",
        "- Medical Imaging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example: Using a pre-trained vision model\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "### Natural Language Processing\n",
        "- Machine Translation\n",
        "- Text Generation\n",
        "- Sentiment Analysis\n",
        "- Question Answering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: 'I love deep learning!'\n",
            "Result: {'label': 'POSITIVE', 'score': 0.7999999999999999}\n",
            "\n",
            "Text: 'Deep learning is revolutionizing AI!'\n",
            "Result: {'label': 'POSITIVE', 'score': 0.7999999999999999}\n",
            "\n",
            "Text: 'This is a neutral statement.'\n",
            "Result: {'label': 'NEUTRAL', 'score': 0.5}\n"
          ]
        }
      ],
      "source": [
        "# Example: Simple sentiment analysis implementation\n",
        "# Note: Transformers library has dependency conflicts in this environment\n",
        "\n",
        "def simple_sentiment_analysis(text):\n",
        "    \"\"\"Simple rule-based sentiment analysis\"\"\"\n",
        "    positive_words = ['love', 'great', 'amazing', 'excellent', 'revolutionizing', \n",
        "                     'fantastic', 'wonderful', 'good', 'awesome', 'brilliant']\n",
        "    negative_words = ['hate', 'bad', 'terrible', 'awful', 'horrible', \n",
        "                     'disappointing', 'poor', 'worst', 'failed']\n",
        "    \n",
        "    text_lower = text.lower()\n",
        "    pos_count = sum(1 for word in positive_words if word in text_lower)\n",
        "    neg_count = sum(1 for word in negative_words if word in text_lower)\n",
        "    \n",
        "    if pos_count > neg_count:\n",
        "        return {'label': 'POSITIVE', 'score': min(0.7 + pos_count * 0.1, 0.99)}\n",
        "    elif neg_count > pos_count:\n",
        "        return {'label': 'NEGATIVE', 'score': min(0.7 + neg_count * 0.1, 0.99)}\n",
        "    else:\n",
        "        return {'label': 'NEUTRAL', 'score': 0.5}\n",
        "\n",
        "# Test the sentiment analysis\n",
        "result1 = simple_sentiment_analysis('I love deep learning!')\n",
        "print(f\"Text: 'I love deep learning!'\")\n",
        "print(f\"Result: {result1}\")\n",
        "\n",
        "result2 = simple_sentiment_analysis('Deep learning is revolutionizing AI!')\n",
        "print(f\"\\nText: 'Deep learning is revolutionizing AI!'\")\n",
        "print(f\"Result: {result2}\")\n",
        "\n",
        "result3 = simple_sentiment_analysis('This is a neutral statement.')\n",
        "print(f\"\\nText: 'This is a neutral statement.'\")\n",
        "print(f\"Result: {result3}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: The above code is commented out due to dependency conflicts.\n",
            "For production use, ensure proper installation of transformers and its dependencies.\n"
          ]
        }
      ],
      "source": [
        "# Alternative: Using Hugging Face Transformers (when dependencies are properly installed)\n",
        "# Uncomment and run this when transformers library is working:\n",
        "\n",
        "\"\"\"\n",
        "from transformers import pipeline\n",
        "\n",
        "# Example: Advanced sentiment analysis with pre-trained models\n",
        "classifier = pipeline('sentiment-analysis', \n",
        "                     model='cardiffnlp/twitter-roberta-base-sentiment-latest')\n",
        "\n",
        "result = classifier('I love deep learning!')\n",
        "print(f\"Advanced result: {result}\")\n",
        "\n",
        "# You can also use other models:\n",
        "# classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
        "\"\"\"\n",
        "\n",
        "print(\"Note: The above code is commented out due to dependency conflicts.\")\n",
        "print(\"For production use, ensure proper installation of transformers and its dependencies.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "### Emerging Applications\n",
        "- Autonomous Vehicles\n",
        "- Drug Discovery\n",
        "- Climate Modeling\n",
        "- Creative Arts (AI Generation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## 1.4 Modern Architectures\n",
        "\n",
        "### Transformer Architecture\n",
        "\n",
        "The Transformer architecture, introduced in the paper 'Attention Is All You Need', has revolutionized natural language processing (NLP) by enabling models to handle long-range dependencies and parallelize training.\n",
        "\n",
        "Key components:\n",
        "1. Self-Attention Mechanism: Allows the model to weigh the importance of different words in a sentence.\n",
        "2. Positional Encoding: Adds information about the position of words in a sequence.\n",
        "3. Multi-Head Attention: Improves the model's ability to focus on different parts of the input.\n",
        "4. Feed-Forward Networks: Applies non-linear transformations to the input.\n",
        "\n",
        "### Generative Adversarial Networks (GANs)\n",
        "\n",
        "GANs consist of two neural networks, a generator and a discriminator, that compete against each other. The generator creates fake data, while the discriminator tries to distinguish between real and fake data.\n",
        "\n",
        "Applications:\n",
        "- Image generation\n",
        "- Data augmentation\n",
        "- Style transfer\n",
        "\n",
        "### Variational Autoencoders (VAEs)\n",
        "\n",
        "VAEs are generative models that learn to encode input data into a latent space and then decode it back to the original space. They are used for generating new data samples and learning data representations.\n",
        "\n",
        "Applications:\n",
        "- Image generation\n",
        "- Anomaly detection\n",
        "- Data compression\n",
        "\n",
        "### Diffusion Models\n",
        "\n",
        "Diffusion models are a class of generative models that learn to reverse a diffusion process, which gradually adds noise to data. They have shown impressive results in generating high-quality images.\n",
        "\n",
        "Applications:\n",
        "- Image generation\n",
        "- Text-to-image synthesis\n",
        "- Super-resolution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## 1.5 Large Models\n",
        "\n",
        "| Model | Company | Size (Parameters) | Properties |\n",
        "|-------|---------|-------------------|------------|\n",
        "| GPT-3 | OpenAI | 175 billion | Few-shot learning, Text generation |\n",
        "| BERT | Google | 340 million | Bidirectional, Pre-training for NLP |\n",
        "| T5 | Google | 11 billion | Text-to-text framework |\n",
        "| DALL-E | OpenAI | 12 billion | Text-to-image generation |\n",
        "| GPT-4 | OpenAI | 1 trillion+ | Multimodal capabilities |\n",
        "| Gemini | Google DeepMind | 500 billion | Advanced reasoning, Multimodal |\n",
        "| Claude 3 | Anthropic | 100 billion | Safety-focused, Conversational AI |\n",
        "| Sora | Microsoft | 200 billion | Text-to-video generation |\n",
        "| Google Titans | Google | 1.5 trillion | Advanced NLP, Multimodal |\n",
        "| LLama3 | Meta | 1 trillion | Multimodal, Advanced reasoning |\n",
        "| DeepSeek | DeepSeek Co. | 800 billion | Multimodal, Advanced search capabilities |\n",
        "| Grok | xAI | 900 billion | Advanced reasoning, Conversational AI |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## 1.6 GPU and AI Chips\n",
        "\n",
        "| Chip | Manufacturer | Key Features |\n",
        "|------|--------------|---------------|\n",
        "| A100 | NVIDIA | High performance, Tensor Cores, Multi-instance GPU |\n",
        "| V100 | NVIDIA | Tensor Cores, High memory bandwidth |\n",
        "| TPU v4 | Google | Optimized for TensorFlow, High efficiency |\n",
        "| Habana Gaudi | Intel | High throughput, Cost-effective |\n",
        "| M1 | Apple | Unified memory architecture, High efficiency |\n",
        "| Ascend 910 | Huawei | High performance, AI-specific optimizations |\n",
        "| AMD Instinct MI100 | AMD | High performance, ROCm support |\n",
        "| Cerebras CS-2 | Cerebras | Wafer-scale engine, High compute density |\n",
        "| Blackwell | NVIDIA | Next-gen performance, Enhanced AI capabilities |\n",
        "| HBM3e | Hynix | Enhanced bandwidth, Low power consumption |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## 1.7 AI Developer Tools\n",
        "\n",
        "### 1.7.1 Frameworks and Libraries\n",
        "- TensorFlow: An open-source platform for machine learning.\n",
        "- PyTorch: An open-source machine learning library based on the Torch library.\n",
        "- Keras: A high-level neural networks API, written in Python and capable of running on top of TensorFlow.\n",
        "- Scikit-learn: A machine learning library for the Python programming language.\n",
        "- Hugging Face Transformers: A library for state-of-the-art NLP models.\n",
        "\n",
        "### 1.7.2 Development Environments\n",
        "- Jupyter Notebook: An open-source web application that allows you to create and share documents that contain live code, equations, visualizations, and narrative text.\n",
        "- Google Colab: A free Jupyter notebook environment that runs entirely in the cloud.\n",
        "- VS Code: A source-code editor made by Microsoft for Windows, Linux, and macOS.\n",
        "- PyCharm: An integrated development environment (IDE) used in computer programming, specifically for the Python language.\n",
        "\n",
        "### 1.7.3 Model Deployment and Serving\n",
        "- TensorFlow Serving: A flexible, high-performance serving system for machine learning models, designed for production environments.\n",
        "- TorchServe: A flexible and easy-to-use tool for serving PyTorch models.\n",
        "- ONNX Runtime: A cross-platform, high-performance scoring engine for Open Neural Network Exchange (ONNX) models.\n",
        "- FastAPI: A modern, fast (high-performance), web framework for building APIs with Python 3.6+ based on standard Python type hints.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.7.4 Experiment Tracking and Management\n",
        "- MLflow: An open-source platform for managing the end-to-end machine learning lifecycle.\n",
        "- Weights & Biases: A tool for experiment tracking, model optimization, and dataset versioning.\n",
        "- Neptune.ai: A metadata store for MLOps, built for research and production teams that run a lot of experiments.\n",
        "- MLflow: An open-source platform for managing the end-to-end machine learning lifecycle.\n",
        "- Weights & Biases: A tool for experiment tracking, model optimization, and dataset versioning.\n",
        "- Neptune.ai: A metadata store for MLOps, built for research and production teams that run a lot of experiments.\n",
        "- Comet.ml: A machine learning platform that allows data scientists and AI practitioners to track, compare, explain, and optimize experiments and models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## 1.8 Quantum Computers\n",
        "\n",
        "| Quantum Computer | Manufacturer | Qubits | Key Features |\n",
        "|------------------|--------------|--------|--------------|\n",
        "| Bristlecone | Google | 72 | Error correction, Scalable architecture |\n",
        "| D-Wave Advantage | D-Wave Systems | 5000+ | Quantum annealing, Optimization problems |\n",
        "| Google Quantum AI | Google | 72 | Quantum supremacy, Error correction |\n",
        "| Honeywell H1 | Honeywell | 10 | High fidelity, Trapped ion technology |\n",
        "| IBM Q System | IBM | 27 | High coherence times, Cloud access |\n",
        "| IBM Quantum System One | IBM | 65 | High coherence times, Scalable architecture |\n",
        "| IonQ Harmony | IonQ | 11 | Trapped ion technology, High fidelity |\n",
        "| IonQ System | IonQ | 32 | Trapped ion technology, High fidelity |\n",
        "| Origin Wukong | Wukong | 50 | High performance, Quantum supremacy |\n",
        "| Rigetti Aspen-9 | Rigetti Computing | 32 | Hybrid quantum-classical computing |\n",
        "| Rigetti Quantum | Rigetti Computing| 40 | High coherence times, Scalable architecture |\n",
        "| Sycamore | Google | 54 | Quantum supremacy, Error correction |\n",
        "| Zuchongzhi | University of Science and Technology of China | 66 | Quantum supremacy, High performance |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discussions\n",
        "\n",
        "Summary:\n",
        "- This chapter introduced fundamental deep learning concepts and related technologies.\n",
        "- We explored modern applications across business and emerging technologies.\n",
        "\n",
        "Questions:\n",
        "1. How do diffusion models differ from transformer models?\n",
        "2. What makes Transformer architectures a breakthrough compared to older NLP models?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "aibookgithub",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "rise": {
      "autolaunch": false,
      "center": true,
      "controls": true,
      "enable_chalkboard": true,
      "enable_spotlight": true,
      "height": 800,
      "history": true,
      "overlay": "<div class='my-top-bar'>Deep Learning</div>",
      "progress": true,
      "scroll": true,
      "slideNumber": true,
      "theme": "simple",
      "transition": "slide",
      "width": 1200
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
