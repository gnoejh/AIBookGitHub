{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/gnoejh/ict1022/blob/main/Architectures/alexnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet: A Deep Convolutional Neural Network\n",
    "\n",
    "## Introduction\n",
    "\n",
    "AlexNet is a convolutional neural network architecture developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton. It was presented in their 2012 paper \"ImageNet Classification with Deep Convolutional Neural Networks\" and won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012 with a top-5 error rate of 15.3%, compared to 26.2% achieved by the second-best entry.\n",
    "\n",
    "This network marked a breakthrough in the field of computer vision and deep learning, showing that deep learning models could significantly outperform traditional computer vision techniques on large-scale image classification tasks.\n",
    "\n",
    "## Historical Importance\n",
    "\n",
    "AlexNet's victory in the 2012 ILSVRC is often cited as a key moment in the history of deep learning, often referred to as the moment when deep learning \"took off\". The success of AlexNet demonstrated:\n",
    "\n",
    "1. The power of deep convolutional neural networks for image recognition\n",
    "2. The importance of GPUs for training large neural networks\n",
    "3. The effectiveness of techniques like ReLU activations and dropout for deep network training\n",
    "\n",
    "Following AlexNet, CNNs became the dominant approach to many computer vision tasks, leading to the development of other influential architectures like VGGNet, GoogLeNet, and ResNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Overview\n",
    "\n",
    "AlexNet consists of 8 layers:\n",
    "- 5 convolutional layers\n",
    "- 3 fully-connected layers\n",
    "\n",
    "The network also includes max-pooling layers, ReLU (Rectified Linear Unit) activations, and dropout regularization.\n",
    "\n",
    "### Key architectural features:\n",
    "\n",
    "1. **Input**: 227×227×3 images\n",
    "2. **First Convolutional Layer**: 96 kernels of size 11×11×3 with a stride of 4, followed by max pooling\n",
    "3. **Second Convolutional Layer**: 256 kernels of size 5×5×48, followed by max pooling\n",
    "4. **Third, Fourth, and Fifth Convolutional Layers**: Various kernel sizes (3×3)\n",
    "5. **Fully-Connected Layers**: Two layers of 4096 neurons each\n",
    "6. **Output Layer**: 1000-way softmax (for ImageNet's 1000 classes)\n",
    "\n",
    "### Notable techniques used in AlexNet:\n",
    "\n",
    "- **ReLU Activation**: Used instead of tanh or sigmoid, which helped reduce training time\n",
    "- **Local Response Normalization (LRN)**: Applied after some layers to aid generalization\n",
    "- **Overlapping Pooling**: Improved accuracy and reduced overfitting\n",
    "- **Dropout**: Applied to fully connected layers to prevent overfitting\n",
    "- **Data Augmentation**: Random crops and horizontal flips to artificially expand the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation with PyTorch\n",
    "\n",
    "Let's implement the AlexNet architecture using PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "!pip install torch torchvision matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the AlexNet model\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "        # Feature extraction layers\n",
    "        self.features = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            # Layer 3\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Layer 4\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Layer 5\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        \n",
    "        # Classification layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of AlexNet\n",
    "model = AlexNet(num_classes=1000).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pre-Trained AlexNet from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained AlexNet model from torchvision\n",
    "pretrained_model = torchvision.models.alexnet(pretrained=True)\n",
    "pretrained_model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Load ImageNet class labels\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "# Download ImageNet class labels if needed\n",
    "try:\n",
    "    url = \"https://raw.githubusercontent.com/pytorch/examples/master/imagenet/imagenet_classes.txt\"\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        classes = [line.decode('utf-8').strip() for line in response.readlines()]\n",
    "except:\n",
    "    # Fallback to a smaller subset if download fails\n",
    "    classes = [f\"Class_{i}\" for i in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification with Pre-trained AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define image preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to make predictions on an image\n",
    "def predict_image(image_path):\n",
    "    # Load and preprocess the image\n",
    "    img = Image.open(image_path)\n",
    "    img_t = preprocess(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0).to(device)\n",
    "    \n",
    "    # Make a prediction\n",
    "    with torch.no_grad():\n",
    "        output = pretrained_model(batch_t)\n",
    "    \n",
    "    # Get the top 5 predictions\n",
    "    _, indices = torch.sort(output, descending=True)\n",
    "    percentages = torch.nn.functional.softmax(output, dim=1)[0] * 100\n",
    "    results = [(classes[idx], percentages[idx].item()) for idx in indices[0][:5]]\n",
    "    \n",
    "    # Display the image\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Top predictions:\")\n",
    "    \n",
    "    # Display the top 5 predictions\n",
    "    for i, (cls, prob) in enumerate(results):\n",
    "        plt.text(5, 30 + i*20, f\"{cls}: {prob:.2f}%\", fontsize=12, \n",
    "                 bbox=dict(facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# To use this function:\n",
    "# predict_image('path/to/your/image.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing AlexNet Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_filters(layer_index=0):\n",
    "    \"\"\"\n",
    "    Visualize filters from a specific convolutional layer\n",
    "    layer_index: Index of the convolutional layer (0 for the first layer)\n",
    "    \"\"\"\n",
    "    # Get the filter weights\n",
    "    filters = pretrained_model.features[layer_index].weight.data.cpu().numpy()\n",
    "    \n",
    "    # Number of filters\n",
    "    num_filters = filters.shape[0]\n",
    "    n_cols = 8  # Number of columns in the grid\n",
    "    n_rows = num_filters // n_cols + (1 if num_filters % n_cols != 0 else 0)\n",
    "    \n",
    "    # Create figure for all filters\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 2))\n",
    "    \n",
    "    for i in range(n_rows * n_cols):\n",
    "        row, col = i // n_cols, i % n_cols\n",
    "        if i < num_filters:\n",
    "            # Normalize the filter for better visualization\n",
    "            filt = filters[i].transpose(1, 2, 0)\n",
    "            filt = (filt - filt.min()) / (filt.max() - filt.min() + 1e-5)\n",
    "            \n",
    "            if n_rows > 1:\n",
    "                axes[row, col].imshow(filt)\n",
    "                axes[row, col].set_title(f'Filter {i}')\n",
    "                axes[row, col].axis('off')\n",
    "            else:\n",
    "                axes[col].imshow(filt)\n",
    "                axes[col].set_title(f'Filter {i}')\n",
    "                axes[col].axis('off')\n",
    "        else:\n",
    "            if n_rows > 1:\n",
    "                axes[row, col].axis('off')\n",
    "            else:\n",
    "                axes[col].axis('off')\n",
    "                \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"Layer {layer_index} Filters\", fontsize=16)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the first convolutional layer filters (96 filters)\n",
    "visualize_filters(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(image_path):\n",
    "    \"\"\"\n",
    "    Visualize feature maps produced by the first convolutional layer\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(image_path)\n",
    "    img_t = preprocess(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0).to(device)\n",
    "    \n",
    "    # Create a hook to capture feature maps\n",
    "    feature_maps = []\n",
    "    \n",
    "    def hook_fn(module, input, output):\n",
    "        feature_maps.append(output.detach().cpu())\n",
    "    \n",
    "    # Register the hook on the first convolutional layer\n",
    "    hook = pretrained_model.features[0].register_forward_hook(hook_fn)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        pretrained_model(batch_t)\n",
    "    \n",
    "    # Remove the hook\n",
    "    hook.remove()\n",
    "    \n",
    "    # Get feature maps\n",
    "    feature_map = feature_maps[0][0]\n",
    "    \n",
    "    # Plot the original image\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot feature maps\n",
    "    n = min(16, feature_map.size(0))  # Display up to 16 feature maps\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    for i in range(n):\n",
    "        a = fig.add_subplot(4, 4, i+1)\n",
    "        img_map = feature_map[i].numpy()\n",
    "        img_map = (img_map - img_map.min()) / (img_map.max() - img_map.min() + 1e-5)\n",
    "        plt.imshow(img_map, cmap='viridis')\n",
    "        plt.axis('off')\n",
    "        a.set_title(f'Feature Map {i}')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('First Layer Feature Maps', fontsize=20)\n",
    "    plt.subplots_adjust(top=0.93)\n",
    "    plt.show()\n",
    "\n",
    "# To use this function:\n",
    "# visualize_feature_maps('path/to/your/image.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet Performance and Historical Context\n",
    "\n",
    "### Performance on ImageNet\n",
    "\n",
    "| Model | Top-1 Accuracy | Top-5 Accuracy |\n",
    "|-------|---------------|---------------|\n",
    "| AlexNet (2012) | 57.1% | 80.2% |\n",
    "| VGG-16 (2014) | 71.3% | 90.1% |\n",
    "| ResNet-50 (2015) | 76.0% | 92.9% |\n",
    "| EfficientNet-B7 (2019) | 84.3% | 97.0% |\n",
    "\n",
    "### Impact and Legacy\n",
    "\n",
    "AlexNet's impact on deep learning and computer vision has been profound:\n",
    "\n",
    "1. **Paradigm Shift**: Demonstrated that deep learning can outperform traditional computer vision methods\n",
    "2. **GPU Adoption**: Popularized the use of GPUs for deep learning\n",
    "3. **Architectural Innovations**: ReLU activations, dropout regularization, and data augmentation became standard practices\n",
    "4. **Foundation for Future Networks**: Inspired subsequent CNN architectures like VGGNet, GoogLeNet, and ResNet\n",
    "\n",
    "### Limitations\n",
    "\n",
    "While groundbreaking in 2012, AlexNet has several limitations:\n",
    "\n",
    "- High computational requirements relative to its accuracy\n",
    "- Large number of parameters (60 million) leading to overfitting risk\n",
    "- Limited depth compared to modern architectures\n",
    "- Uses Local Response Normalization, which has been largely replaced by Batch Normalization in modern networks\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "AlexNet represents a pivotal moment in the history of artificial intelligence and computer vision. Its success in the 2012 ImageNet competition demonstrated the potential of deep learning approaches and sparked the deep learning revolution that continues to this day. While newer architectures have surpassed its performance, AlexNet's historical importance and influence on neural network design principles ensure its place in the history of artificial intelligence."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
