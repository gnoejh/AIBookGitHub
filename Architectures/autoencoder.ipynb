{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/gnoejh/ict1022/blob/main/Architectures/autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "Autoencoders are a type of neural network architecture designed to learn efficient data encodings in an unsupervised manner. They compress (encode) input data into a lower-dimensional latent representation and then reconstruct (decode) the original input from this representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Overview\n",
    "\n",
    "An autoencoder consists of two main components:\n",
    "\n",
    "1. **Encoder**: Compresses the input into a latent-space representation\n",
    "2. **Decoder**: Reconstructs the input from the latent-space representation\n",
    "\n",
    "![Autoencoder Architecture](https://miro.medium.com/v2/resize:fit:1400/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png)\n",
    "\n",
    "The central idea is to force the network to learn a compressed representation of the data by creating a \"bottleneck\" in the architecture. This forces the network to retain only the most essential features needed for reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Formulation\n",
    "\n",
    "Given input data $x$, an autoencoder aims to learn:\n",
    "\n",
    "1. An encoder function $f(x)$ that maps the input to a hidden representation $h = f(x)$\n",
    "2. A decoder function $g(h)$ that reconstructs the input $\\hat{x} = g(h) = g(f(x))$\n",
    "\n",
    "The network is trained to minimize a reconstruction error or loss function:\n",
    "\n",
    "$$L(x, \\hat{x}) = L(x, g(f(x)))$$\n",
    "\n",
    "Common loss functions include Mean Squared Error (MSE) for continuous data and Binary Cross-Entropy for binary data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Autoencoders\n",
    "\n",
    "### 1. Vanilla Autoencoder\n",
    "The simplest form using fully connected layers with a smaller hidden layer to force compression.\n",
    "\n",
    "### 2. Undercomplete Autoencoder\n",
    "Uses a hidden layer smaller than the input to learn compressed representations.\n",
    "\n",
    "### 3. Sparse Autoencoder\n",
    "Adds a sparsity penalty to the loss function, encouraging the network to activate only a small number of neurons.\n",
    "\n",
    "### 4. Denoising Autoencoder (DAE)\n",
    "Trained to reconstruct clean data from corrupted inputs, improving robustness and generalization.\n",
    "\n",
    "### 5. Contractive Autoencoder (CAE)\n",
    "Adds a regularization term to make the learned representations more robust to small variations in input.\n",
    "\n",
    "### 6. Convolutional Autoencoder\n",
    "Uses convolutional layers instead of fully connected layers, making them suitable for image data.\n",
    "\n",
    "### 7. Variational Autoencoder (VAE)\n",
    "A probabilistic variant that learns a probability distribution of the latent space, enabling generative capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Example: Basic Autoencoder\n",
    "\n",
    "Here's a simple implementation of an autoencoder using TensorFlow/Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Input dimension\n",
    "input_dim = 784  # For MNIST dataset (28x28 images flattened)\n",
    "\n",
    "# Encoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(128, activation='relu')(input_layer)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "latent = Dense(32, activation='relu')(encoded)  # Bottleneck layer\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(64, activation='relu')(latent)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "output_layer = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# Autoencoder model (full)\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "\n",
    "# Separate encoder model\n",
    "encoder = Model(input_layer, latent)\n",
    "\n",
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Model summary\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Example: Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "# Input\n",
    "input_img = Input(shape=(28, 28, 1))  # MNIST images: 28x28x1\n",
    "\n",
    "# Encoder\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)  # 7x7x16\n",
    "\n",
    "# Decoder\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Autoencoder model\n",
    "conv_autoencoder = Model(input_img, decoded)\n",
    "conv_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Model summary\n",
    "conv_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess data\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "# Normalize and reshape data\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape for the dense autoencoder\n",
    "x_train_flatten = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test_flatten = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "# Reshape for the convolutional autoencoder\n",
    "x_train_conv = x_train.reshape((len(x_train), 28, 28, 1))\n",
    "x_test_conv = x_test.reshape((len(x_test), 28, 28, 1))\n",
    "\n",
    "# Train the dense autoencoder\n",
    "history = autoencoder.fit(\n",
    "    x_train_flatten, x_train_flatten,\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test_flatten, x_test_flatten)\n",
    ")\n",
    "\n",
    "# Visualize training progress\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of Autoencoders\n",
    "\n",
    "1. **Dimensionality Reduction**: Alternative to PCA, especially for non-linear relationships\n",
    "2. **Image Denoising**: Removing noise from images (with denoising autoencoders)\n",
    "3. **Feature Extraction**: Learning meaningful representations for downstream tasks\n",
    "4. **Anomaly Detection**: Identifying data points that differ from the norm\n",
    "5. **Image Generation**: Particularly with VAEs and other generative variants\n",
    "6. **Data Compression**: Creating compact representations of data\n",
    "7. **Recommender Systems**: Learning latent representations of user preferences\n",
    "8. **Drug Discovery**: Learning molecular fingerprints for drug candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Autoencoder Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode and decode some test images\n",
    "decoded_imgs = autoencoder.predict(x_test_flatten)\n",
    "\n",
    "# Plot original and reconstructed images\n",
    "n = 10  # Number of images to display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Original images\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # Reconstructed images\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Latent Space\n",
    "\n",
    "If we reduce the latent space to 2 dimensions, we can visualize the encoded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simpler autoencoder with 2D latent space for visualization\n",
    "input_layer = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_layer)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "latent = Dense(2, activation='linear')(encoded)  # 2D bottleneck for visualization\n",
    "\n",
    "decoded = Dense(64, activation='relu')(latent)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "output_layer = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "vis_autoencoder = Model(input_layer, output_layer)\n",
    "vis_encoder = Model(input_layer, latent)\n",
    "vis_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train\n",
    "vis_autoencoder.fit(x_train_flatten, x_train_flatten, epochs=15, batch_size=256, validation_data=(x_test_flatten, x_test_flatten))\n",
    "\n",
    "# Encode the data to 2D latent space\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train_flatten = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "\n",
    "# Encode the data\n",
    "encoded_data = vis_encoder.predict(x_train_flatten)\n",
    "\n",
    "# Plot the 2D latent space with colors corresponding to digits\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(encoded_data[:, 0], encoded_data[:, 1], c=y_train, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('2D Latent Space of MNIST Digits')\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages and Limitations\n",
    "\n",
    "### Advantages\n",
    "- Unsupervised learning capability\n",
    "- Effective dimensionality reduction for complex data\n",
    "- Can capture non-linear relationships\n",
    "- Versatile architecture that can be adapted to different data types\n",
    "\n",
    "### Limitations\n",
    "- Simple autoencoders may learn to simply copy the input\n",
    "- Can be challenging to interpret the learned features\n",
    "- May require careful tuning of the architecture\n",
    "- Standard autoencoders are not true generative models (unlike VAEs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Context\n",
    "\n",
    "The concept of autoencoders has been around since the 1980s, with early work by Hinton and the PDP group. They gained renewed interest with the deep learning revolution and have evolved from simple architectures to sophisticated variants like VAEs and denoising autoencoders.\n",
    "\n",
    "Key milestones include:\n",
    "- 1986: First descriptions of autoencoders for dimensionality reduction\n",
    "- 2006: Deep belief networks and layerwise pretraining\n",
    "- 2008: Denoising autoencoders introduced by Vincent et al.\n",
    "- 2013: Variational autoencoders introduced by Kingma and Welling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Hinton, G. E., & Zemel, R. S. (1994). [Autoencoders, Minimum Description Length, and Helmholtz Free Energy](https://proceedings.neurips.cc/paper/1993/file/9e3cfc48eccf81a0d57663e129aef3cb-Paper.pdf). NIPS.\n",
    "- Vincent, P., et al. (2008). [Extracting and Composing Robust Features with Denoising Autoencoders](https://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdf). ICML.\n",
    "- Kingma, D. P., & Welling, M. (2013). [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114). ICLR.\n",
    "- Goodfellow, I., Bengio, Y., & Courville, A. (2016). [Deep Learning](https://www.deeplearningbook.org/). MIT Press. Chapter 14.\n",
    "- Bank, D., Koenigstein, N., & Giryes, R. (2020). [Autoencoders](https://arxiv.org/abs/2003.05991). arXiv preprint."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
