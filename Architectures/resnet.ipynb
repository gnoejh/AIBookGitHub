{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a href=\"https://colab.research.google.com/github/gnoejh/ict1022/blob/main/Architectures/resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Residual Networks (ResNet)\n",
                "\n",
                "## Introduction\n",
                "\n",
                "Residual Networks (ResNets) represent a breakthrough in deep neural network design that addressed the degradation problem in very deep networks. Introduced by Kaiming He et al. from Microsoft Research in their seminal 2015 paper [\"Deep Residual Learning for Image Recognition\"](https://arxiv.org/abs/1512.03385), ResNets won the ILSVRC 2015 classification competition and have become one of the most influential architectures in deep learning."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The Degradation Problem\n",
                "\n",
                "Prior to ResNet, researchers observed that simply stacking more layers led to higher training error. This counter-intuitive phenomenon, called the degradation problem, wasn't caused by overfitting, but by the optimization difficulty in training very deep networks.\n",
                "\n",
                "![Degradation Problem](https://miro.medium.com/max/600/1*5qUe8VDuN4Jie_6eFFpXig.png)\n",
                "\n",
                "*Image showing training/validation error increasing with depth in plain networks*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Key Innovation: Residual Learning\n",
                "\n",
                "The core insight of ResNet is the introduction of **residual connections** (also called skip connections or shortcut connections). Instead of learning a direct mapping $H(x)$, the network learns the residual function $F(x) = H(x) - x$, which can be rearranged as $H(x) = F(x) + x$.\n",
                "\n",
                "This simple yet profound change facilitates the flow of gradients through the network during backpropagation, allowing for much deeper architectures.\n",
                "\n",
                "![Residual Block](https://miro.medium.com/max/700/1*6xp-IY-M8lEEEN_W7BpWPA.png)\n",
                "\n",
                "*The basic residual block structure*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ResNet Architecture\n",
                "\n",
                "ResNet comes in various depths, with ResNet-18, ResNet-34, ResNet-50, ResNet-101, and ResNet-152 being the most common variants (the number indicates the layer count).\n",
                "\n",
                "### Basic Building Blocks\n",
                "\n",
                "1. **Basic Block**: Used in shallower networks (ResNet-18, ResNet-34)\n",
                "   - Two 3\u00d73 convolutional layers with batch normalization and ReLU\n",
                "   - Identity shortcut connection\n",
                "\n",
                "2. **Bottleneck Block**: Used in deeper networks (ResNet-50+)\n",
                "   - 1\u00d71 conv for dimension reduction\n",
                "   - 3\u00d73 conv for filtering\n",
                "   - 1\u00d71 conv for dimension restoration\n",
                "   - Identity shortcut connection\n",
                "\n",
                "![ResNet Architecture](https://miro.medium.com/max/700/1*zS2ChIMwQ8x8lslF7QK9xQ.png)\n",
                "\n",
                "*Comparing basic and bottleneck blocks*\n",
                "\n",
                "### Overall Structure\n",
                "\n",
                "1. Initial 7\u00d77 convolution with stride 2\n",
                "2. 3\u00d73 max pooling with stride 2\n",
                "3. Four stages of residual blocks (with doubling of channels and halving of dimensions at each stage)\n",
                "4. Global average pooling\n",
                "5. Fully connected layer with softmax"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "# Basic residual block implementation\n",
                "class BasicBlock(nn.Module):\n",
                "    expansion = 1\n",
                "    \n",
                "    def __init__(self, in_channels, out_channels, stride=1):\n",
                "        super(BasicBlock, self).__init__()\n",
                "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
                "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
                "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
                "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
                "        \n",
                "        # Shortcut connection to match dimensions\n",
                "        self.shortcut = nn.Sequential()\n",
                "        if stride != 1 or in_channels != out_channels:\n",
                "            self.shortcut = nn.Sequential(\n",
                "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
                "                nn.BatchNorm2d(out_channels)\n",
                "            )\n",
                "    \n",
                "    def forward(self, x):\n",
                "        out = F.relu(self.bn1(self.conv1(x)))\n",
                "        out = self.bn2(self.conv2(out))\n",
                "        out += self.shortcut(x)  # Add the shortcut connection\n",
                "        out = F.relu(out)        # Apply ReLU after addition\n",
                "        return out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bottleneck block for deeper ResNets\n",
                "class Bottleneck(nn.Module):\n",
                "    expansion = 4\n",
                "    \n",
                "    def __init__(self, in_channels, out_channels, stride=1):\n",
                "        super(Bottleneck, self).__init__()\n",
                "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
                "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
                "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
                "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
                "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n",
                "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
                "        \n",
                "        # Shortcut connection\n",
                "        self.shortcut = nn.Sequential()\n",
                "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
                "            self.shortcut = nn.Sequential(\n",
                "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
                "                nn.BatchNorm2d(out_channels * self.expansion)\n",
                "            )\n",
                "    \n",
                "    def forward(self, x):\n",
                "        out = F.relu(self.bn1(self.conv1(x)))\n",
                "        out = F.relu(self.bn2(self.conv2(out)))\n",
                "        out = self.bn3(self.conv3(out))\n",
                "        out += self.shortcut(x)  # Add the shortcut connection\n",
                "        out = F.relu(out)        # Apply ReLU after addition\n",
                "        return out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Complete ResNet Implementation\n",
                "class ResNet(nn.Module):\n",
                "    def __init__(self, block, num_blocks, num_classes=1000):\n",
                "        super(ResNet, self).__init__()\n",
                "        self.in_channels = 64\n",
                "        \n",
                "        # Initial convolution\n",
                "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
                "        self.bn1 = nn.BatchNorm2d(64)\n",
                "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
                "        \n",
                "        # Residual blocks\n",
                "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
                "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
                "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
                "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
                "        \n",
                "        # Classification head\n",
                "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
                "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
                "    \n",
                "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
                "        strides = [stride] + [1] * (num_blocks - 1)\n",
                "        layers = []\n",
                "        for stride in strides:\n",
                "            layers.append(block(self.in_channels, out_channels, stride))\n",
                "            self.in_channels = out_channels * block.expansion\n",
                "        return nn.Sequential(*layers)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = F.relu(self.bn1(self.conv1(x)))\n",
                "        x = self.maxpool(x)\n",
                "        \n",
                "        x = self.layer1(x)\n",
                "        x = self.layer2(x)\n",
                "        x = self.layer3(x)\n",
                "        x = self.layer4(x)\n",
                "        \n",
                "        x = self.avgpool(x)\n",
                "        x = torch.flatten(x, 1)\n",
                "        x = self.fc(x)\n",
                "        \n",
                "        return x\n",
                "\n",
                "# Define specific variants of ResNet\n",
                "def ResNet18():\n",
                "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
                "\n",
                "def ResNet50():\n",
                "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
                "\n",
                "def ResNet152():\n",
                "    return ResNet(Bottleneck, [3, 8, 36, 3])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Using Pre-trained ResNet Models\n",
                "\n",
                "Modern deep learning frameworks provide pre-trained ResNet models that can be used for inference or fine-tuning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Using pre-trained ResNet in PyTorch\n",
                "import torch\n",
                "import torchvision.models as models\n",
                "from torchvision import transforms\n",
                "from PIL import Image\n",
                "\n",
                "# Load pre-trained ResNet-50\n",
                "model = models.resnet50(pretrained=True)\n",
                "model.eval()\n",
                "\n",
                "# Prepare image preprocessing\n",
                "preprocess = transforms.Compose([\n",
                "    transforms.Resize(256),\n",
                "    transforms.CenterCrop(224),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "# Example of image loading and inference\n",
                "def classify_image(image_path):\n",
                "    img = Image.open(image_path)\n",
                "    img_t = preprocess(img)\n",
                "    batch_t = torch.unsqueeze(img_t, 0)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        output = model(batch_t)\n",
                "    \n",
                "    # Load ImageNet class labels\n",
                "    import json\n",
                "    import requests\n",
                "    \n",
                "    labels_URL = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
                "    labels = json.loads(requests.get(labels_URL).text)\n",
                "    \n",
                "    # Get predicted class\n",
                "    _, index = torch.max(output, 1)\n",
                "    predicted_label = labels[index.item()]\n",
                "    \n",
                "    return predicted_label\n",
                "\n",
                "# Example usage (uncomment to use)\n",
                "# label = classify_image('path/to/image.jpg')\n",
                "# print(f\"Predicted class: {label}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Using ResNet in TensorFlow/Keras"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Using pre-trained ResNet in TensorFlow/Keras\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.applications import ResNet50\n",
                "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
                "from tensorflow.keras.preprocessing import image\n",
                "import numpy as np\n",
                "\n",
                "# Load pre-trained ResNet-50\n",
                "model = ResNet50(weights='imagenet')\n",
                "\n",
                "# Function to classify an image\n",
                "def classify_image_tf(image_path):\n",
                "    img = image.load_img(image_path, target_size=(224, 224))\n",
                "    x = image.img_to_array(img)\n",
                "    x = np.expand_dims(x, axis=0)\n",
                "    x = preprocess_input(x)\n",
                "    \n",
                "    preds = model.predict(x)\n",
                "    decoded = decode_predictions(preds, top=3)[0]\n",
                "    \n",
                "    return [(class_name, label, float(score)) for class_name, label, score in decoded]\n",
                "\n",
                "# Example usage (uncomment to use)\n",
                "# predictions = classify_image_tf('path/to/image.jpg')\n",
                "# for _, label, score in predictions:\n",
                "#     print(f\"{label}: {score:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Variations and Extensions of ResNet\n",
                "\n",
                "Since its introduction, many variations of ResNet have been developed:\n",
                "\n",
                "1. **ResNeXt**: Added a cardinality dimension to ResNets, using grouped convolutions\n",
                "2. **Wide ResNet**: Used wider layers (more channels) with reduced depth\n",
                "3. **SE-ResNet**: Integrated Squeeze-and-Excitation blocks for adaptive feature recalibration\n",
                "4. **ResNeSt**: Combined ResNeXt, squeeze-and-excitation, and multi-path representation\n",
                "5. **EfficientNet**: Used neural architecture search to scale depth, width, and resolution\n",
                "\n",
                "![ResNet Variations](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-06_at_10.42.23_PM.png)\n",
                "\n",
                "*Comparison of different ResNet variant block structures*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Applications\n",
                "\n",
                "ResNet has been widely adopted for various computer vision tasks:\n",
                "\n",
                "1. **Image Classification**: The original purpose, achieving SOTA performance on ImageNet\n",
                "2. **Object Detection**: As a backbone for Faster R-CNN, RetinaNet, etc.\n",
                "3. **Semantic Segmentation**: As an encoder in U-Net, DeepLab, etc.\n",
                "4. **Transfer Learning**: Pre-trained ResNets as feature extractors for downstream tasks\n",
                "5. **Video Analysis**: Extended to 3D ResNets for video recognition tasks"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Impact and Legacy\n",
                "\n",
                "ResNet has had a profound impact on deep learning:\n",
                "\n",
                "1. It enabled training of much deeper networks, from tens to hundreds of layers\n",
                "2. The concept of residual learning has been adopted in many other architectures\n",
                "3. Skip connections have become a standard technique in modern network design\n",
                "4. ResNet and its variants continue to serve as strong baselines for computer vision tasks\n",
                "5. The insights from ResNet have influenced architectures in other domains, including NLP and speech recognition"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Further Reading\n",
                "\n",
                "1. He, K., et al. (2015). [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385). CVPR 2016.\n",
                "2. He, K., et al. (2016). [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027). ECCV 2016.\n",
                "3. Xie, S., et al. (2016). [Aggregated Residual Transformations for Deep Neural Networks (ResNeXt)](https://arxiv.org/abs/1611.05431). CVPR 2017.\n",
                "4. Zagoruyko, S., & Komodakis, N. (2016). [Wide Residual Networks](https://arxiv.org/abs/1605.07146). BMVC 2016.\n",
                "5. Hu, J., et al. (2018). [Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507). CVPR 2018."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}